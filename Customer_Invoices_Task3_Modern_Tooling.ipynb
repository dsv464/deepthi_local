{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3170b69-e776-4aa7-936b-0c24b7a39656",
   "metadata": {},
   "source": [
    "# **Task 3 - Modern Tooling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24272729-c715-4b10-a493-fe4e5f78c516",
   "metadata": {},
   "source": [
    "### **============================================================================**\n",
    "## **Why DBT over SSIS**\n",
    "### **============================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ce0277-b468-432f-886c-681b839f01d0",
   "metadata": {},
   "source": [
    "### **1. Easy Testing and Validations :**\n",
    "###     DBT supports built-in tests like not_null/unique test - in .yml. \n",
    "###     It supports - custom data quality checks - singular tests\n",
    "\n",
    "### **2. DBT ELT vs SSIS ETL :**\n",
    "###     DBT follows ELT (Extract-Load-Transform) model. \n",
    "###     It uses warehouse compute power - which execute all transformations directly within the DWH \n",
    "###     This ensures better scalability and performance.\n",
    "\n",
    "### **3. Easier to Deploy, Version control and Automate :**\n",
    "###     DBT integrates easily with Airflow - for orchestration/job scheduling, GitHub - for version controlling\n",
    "\n",
    "### **4. DBT is Open Source and Cloud Specific :**\n",
    "###     DBT-Core is open source and designed specifically for cloud data warehouses\n",
    "\n",
    "### **5. Data Lineage :**\n",
    "###     DBT generates data lineage for both tables and individual columns, making it easy to trace how data flows through the pipeline. \n",
    "###     This helps developers quickly identify the original source of any column used in downstream models/data marts, \n",
    "###     which also makes debugging easier.\n",
    "\n",
    "### **6. Code Reusability :**\n",
    "###     DBT ref() makes the code reusable especially in layered models (Bronze → Silver → Gold) with clear dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47468d2b-c39a-4c43-b788-6ec96d913398",
   "metadata": {},
   "source": [
    "### **============================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8caaa4-ea46-4010-a37b-72ab4bca8e7b",
   "metadata": {},
   "source": [
    "## **NOTE:**\n",
    "### I've worked with both dbt Core integrated with Airflow, as well as dbt Cloud.\n",
    "### Here’s a comparison of the advantages of using dbt Core with Airflow versus dbt Cloud\n",
    "### Below are the key advantages and differences between both approaches:\n",
    "\n",
    "### **============================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08542c8-b5aa-4795-bebb-659db1a0c648",
   "metadata": {},
   "source": [
    "# **Option 1 : DBT-Core for ELT with Airflow for orchestration / scheduling**\n",
    "## ***************************************************************************\n",
    "\n",
    "### **1. Flexible and Cost Effective**  \n",
    "   ### Both DBT Core and Airflow are open-source, which offers full control on the tools without licensing costs. \n",
    "   ### They are flexible to deply in cloud.\n",
    "\n",
    "### **2. DBT ELT Layering**  \n",
    "   ### dbt Core enables clean, version-controlled SQL transformations  directly on DWH. Layering in DBT helps in\n",
    "\n",
    "   ### -> Breaks complex logic into small, reusable models\n",
    "\n",
    "   ### -> Reduces duplication by allowing shared logic across downstream models.\n",
    "\n",
    "### **3. Easy Scheduling**  \n",
    "   ### Airflow helps to schedule and chain dbt runs with full control - which include retry , check for dependancy runs etc.\n",
    "\n",
    "### **4. Easy Git Integration**  \n",
    "   ### Both Airflow and dbt Core can be easily integrated with Git - for version controlling.\n",
    "   ### Airflow can also be integrated with Slack or PagerDuty to notify whenever there is failure in pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c02df17-8082-436b-b1ab-0c4d923a5603",
   "metadata": {},
   "source": [
    "### **============================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade8b629-7602-4b8c-bd3b-8964f98bdb05",
   "metadata": {},
   "source": [
    "# **Option 2 : DBT-Cloud**\n",
    "## ***************************************************************************\n",
    "\n",
    "### **1. Built-in Scheduler**  \n",
    "   ### No need for external tools like Airflow — schedule dbt runs directly using DBT Cron Jobs.\n",
    "\n",
    "### **2. User Friendly Web UI**  \n",
    "   ### Easily develop, run, and monitor dbt models without using the command line.\n",
    "\n",
    "### **3. Centralized Monitoring**  \n",
    "   ### All runs, logs, and errors cab be tracket in one place.\n",
    "\n",
    "### **4. Seamless Git Integration**  \n",
    "   ### We can push, merge, and deploy into GitHub/GitLab directly through the dbt Cloud interface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a553b009-97f1-46e1-9027-3cb0fd21c1f6",
   "metadata": {},
   "source": [
    "### **============================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2997cc-6bf3-4296-b1a0-fc141dc5d731",
   "metadata": {},
   "source": [
    "# **Proposed Migration from SSIS to DBT**\n",
    "## ***************************************************************************\n",
    "\n",
    "### **1. Choose a Cloud DWH Platform and move the raw data into DWH**  \n",
    "   ### Use a Scripts / Cloud Data Transfer Services / ETL Tools to load source data from SSIS into cloud DWH warehouse.\n",
    "\n",
    "### **2. Convert SSIS logic into DBT models**  \n",
    "   ### Design the DBT model structure and rewrite all the transformation logic in SQL into DBT layers.\n",
    "\n",
    "### **3. Add Respective data Tests**  \n",
    "   ### Use dbt’s built-in features to check data quality and describe each model and column.\n",
    "\n",
    "### **4. Schedule and run dbt**  \n",
    "   ### Use dbt Cloud or Airflow to run dbt models.\n",
    "\n",
    "### **============================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcd926f-3d6f-4933-9961-37524ca5c79c",
   "metadata": {},
   "source": [
    "# **Risks in Changing Position Data Processing**\n",
    "## ***************************************************************************\n",
    "\n",
    "### **1. Incorrect Financial Calculations**  \n",
    "  ### Changes in current data logic could lead to incorrect totals.\n",
    "  ### Instead of directly midifying the existing pipeline, build a new pipeline with the logic changes,\n",
    "  ### which correct the known existing issues and monitor the % discrepancies with the existing pipeline.\n",
    "\n",
    "### **2. Broken Reports and Dashboards**  \n",
    "  ### There are chances that the downstream report data may break if these is any change in upstream source.\n",
    "  ### To prevent this, introduce the new logic fields into the report, \n",
    "  ### explain the end-users regarding the discrepancies old vs new - and eventually get rid of the old-incorrect fields.\n",
    "\n",
    "### **3. Reconciliation Issues**  \n",
    "  ### Differences between old (SSIS) and new (dbt) outputs may cause confusion or inconsistencies. \n",
    "  ### Always good to maintain both old and new pipelines, until all the issues are addressed,  \n",
    "  ### communicated to stake-holders and everything is stabilized on the new set-up.\n",
    "\n",
    "### **4. Stakeholder Trust & Compliance Risk**  \n",
    "  ### Any discrepancies in financial data may impact stakeholder and sometimes create audit concerns. \n",
    "  ### To avoid such cases - \n",
    "   ###  -> Do not disturb the old data \n",
    "   ###  -> Lift and shift the existing data as it is into DBT \n",
    "   ###  -> Implement the logic changes to incoming data - post clear communication with stake-holders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5c7c23-cc19-4417-84bd-6e8c887f987c",
   "metadata": {},
   "source": [
    "### **============================================================================**\n",
    "## **Tools Used for Implementation**\n",
    "## ***************************************************************************\n",
    "\n",
    "### **1. Database: SQLite**\n",
    "### **2. Jupyter Notebook**\n",
    "### **3. DBT Core**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
